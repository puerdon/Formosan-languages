import pandas as pd
import base64
import streamlit as st
import streamlit.components.v1 as components
import re
# from pandas_profiling import ProfileReport
from st_aggrid import AgGrid
from st_aggrid.grid_options_builder import GridOptionsBuilder
from st_aggrid.shared import JsCode
# Read sheet from Google
from streamlit_gsheets import GSheetsConnection

import xlsxwriter
from io import BytesIO

LANG_ENG_TABLE = {
"é˜¿ç¾":"Amis",
"æ³°é›…":"Atayal",
"æ’ç£":"Paiwan",
"å¸ƒè¾²":"Bunun",
"å‘å—":"Puyuma",
"é­¯å‡±":"Rukai",
"é„’":"Tsou",
"å¡é‚£å¡é‚£å¯Œ":"Kanakanavu",
"æ‹‰é˜¿é­¯å“‡":"Saaroa",
"è³½å¤":"Saisiyat",
"é›…ç¾":"Yami",
"é‚µ":"Thao",
"å™¶ç‘ªè˜­":"Kavalan",
"å¤ªé­¯é–£":"Truku",
"æ’’å¥‡èŠé›…":"Sakizaya",
"è³½å¾·å…‹":"Seediq"
}

# Initialization
# if 'last_update_time' not in st.session_state:
#     st.session_state['last_update_time'] = 0

def main():
    
    st.set_page_config(layout="wide")
    st.title("å°ç£å—å³¶èªæ–‡æœ¬æ•¸ä½è³‡æ–™åº«")
    st.subheader("Formosan Digital Database")
    
    # st.write(st.session_state['last_update_time'])
    
    st.markdown(
        """
âš ï¸ æ­¤æŸ¥è©¢ç³»çµ±åƒ…ä¾›æ•™å­¸èˆ‡ç ”ç©¶ä¹‹ç”¨ï¼Œå…§å®¹ç‰ˆæ¬Šæ­¸åŸå§‹è³‡æ–™æä¾›è€…æ‰€æœ‰"""
    )

    with st.expander("æŸ¥è©¢æ–¹æ³•"):
        st.markdown('''
            - ğŸ”­ éæ¿¾ï¼šä½¿ç”¨å·¦å´æ¬„åŠŸèƒ½é¸å–®å¯éæ¿¾è³‡æ–™ä¾†æº(å¯å¤šé¸)èˆ‡èªè¨€ï¼Œä¹Ÿå¯ä½¿ç”¨è¯èªæˆ–æ—èªé€²è¡Œé—œéµè©æŸ¥è©¢ã€‚
  - ğŸ” é—œéµè©æŸ¥è©¢æ”¯æ´[æ­£å‰‡è¡¨é”å¼](https://zh.wikipedia.org/zh-tw/æ­£åˆ™è¡¨è¾¾å¼)ã€‚
  - ğŸ¥³ æ—èªç¯„ä¾‹: 
    + æœå°‹ä»¥ mn é–‹é ­çš„å¥å­ï¼šè¼¸å…¥`^mn`ã€‚
    + ç”±æ–¼åŠå½¢çš„`.`å’Œ`?`åœ¨æ­£å‰‡è¡¨é”å¼æœ‰ç‰¹æ®ŠåŠŸèƒ½ï¼Œå› æ­¤è‹¥è¦æœå°‹å‡ºç¾åœ¨æ–‡æœ¬ä¸­çš„åŠå½¢å¥é»å’Œå•è™Ÿã€‚è«‹åœ¨å‰æ–¹åŠ ä¸Šåæ–œç·š(backslash):`\.`å’Œ`\?`ã€‚æœå°‹é€—è™Ÿã€å†’è™Ÿã€é©šå˜†è™Ÿæ¯‹é ˆåŠ ä¸Šåæ–œç·šã€‚
    + æœå°‹ä½œç‚ºå–®è©çš„ aki ï¼Œè€ŒéåŒ…å«æœ‰akiçš„è©å½™ï¼Œè«‹å°‡å–®è©åŒ…åœ¨å…©å€‹`\b`ä¹‹é–“ï¼š`\baki\b`ï¼ˆ`\b`æ„ç‚º word boundaryï¼‰ã€‚
    + æœå°‹æ‰€æœ‰ä»¥ mn é–‹é ­çš„å–®è©ï¼šè¼¸å…¥`\bmn`ã€‚
    + æœå°‹æ‰€æœ‰çš„ ga (æ³°é›…ä¸»é¡Œæ¨™è¨˜)ï¼šè¼¸å…¥`\bga[ ,!\.\?]`ã€‚(é€™ä¸²æœå°‹çš„æ„ç¾©æ˜¯:gaå‰é¢ç‚ºword boundaryï¼Œè€Œgaçš„å¾Œé¢å¯ä»¥å‡ºç¾ç©ºæ ¼ã€é€—è™Ÿã€é©šå˜†è™Ÿã€å¥è™Ÿæˆ–å•è™Ÿå…¶ä¸­ä¹‹ä¸€ã€‚)
    + æœå°‹å–®è© ini æˆ– `ini'`ï¼šè¼¸å…¥`\bini'?\b`
  - ğŸ¤© è¯èªç¯„ä¾‹: 
    + æ‰¾å‡ºä»¥ã€Œå¯èƒ½ã€ä½œç‚ºé–‹é ­çš„å¥å­ï¼šè¼¸å…¥`^å¯èƒ½`ã€‚
    + æ‰¾å‡ºã€Œäº†ã€å‡ºç¾åœ¨å¥å°¾çš„å¥å­ï¼šè¼¸å…¥`äº†$`ã€‚
- ğŸ“š æ’åºï¼šé»é¸æ¨™é¡Œåˆ—ã€‚ä¾‹å¦‚é»é¸`æ—èª`æ¬„ä½æ¨™é¡Œåˆ—å…§çš„ä»»ä½•åœ°æ–¹ï¼Œè³‡æ–™é›†ä¾¿æœƒæ ¹æ“šæ—èªé‡æ–°æ’åºã€‚
        ''')

    # check last updated time:
    last_update_timestamp = get_last_updated_timestamp()
    df = load_data(last_update_timestamp)

    # df = pd.concat([df, user_df], ignore_index=True)
    # pd.set_option('max_colwidth', 600)

    # remap column names
    zh_columns = {
        'Lang_En': 'Language',
        'Lang_Ch': 'èªè¨€_æ–¹è¨€',
        'Ab': 'æ—èª',
        'Ch': 'è¯èª',
        'From': 'ä¾†æº'
    }
    df.rename(columns=zh_columns, inplace=True)

    # set up filtering options
    langs = st.sidebar.selectbox(
        "è«‹é¸æ“‡èªè¨€",
        options=['æ³°é›…', 'å¸ƒè¾²', 'é˜¿ç¾', 'æ’’å¥‡èŠé›…', 'å™¶ç‘ªè˜­', 'é­¯å‡±', 'æ’ç£', 'å‘å—',
                 'è³½å¾·å…‹', 'å¤ªé­¯é–£', 'é„’', 'æ‹‰é˜¿é­¯å“‡', 'å¡é‚£å¡é‚£å¯Œ',
                 'é‚µ', 'è³½å¤', 'é”æ‚Ÿ'],
    )

    sources = st.sidebar.multiselect(
        "è«‹é¸æ“‡è³‡æ–™ä¾†æº",
        options=df[df['Language'] == LANG_ENG_TABLE[langs]]['ä¾†æº'].unique(),
        default=df[df['Language'] == LANG_ENG_TABLE[langs]]['ä¾†æº'].unique())
    
    texts = st.sidebar.radio(
        "è«‹é¸æ“‡é—œéµè©æŸ¥è©¢æ–‡å­—é¡åˆ¥",
        options=['æ—èª', 'è¯èª'],)

    # filter by sources
    s_filt = df['ä¾†æº'].isin(sources)

    # select a language
    if langs == "å™¶ç‘ªè˜­":
        l_filt = df['Language'] == "Kavalan"
    elif langs == "é˜¿ç¾":
        l_filt = df['Language'] == "Amis"
    elif langs == "æ’’å¥‡èŠé›…":
        l_filt = df['Language'] == "Sakizaya"
    elif langs == "é­¯å‡±":
        l_filt = df['Language'] == "Rukai"
    elif langs == "æ’ç£":
        l_filt = df['Language'] == "Paiwan"
    elif langs == "å‘å—":
        l_filt = df['Language'] == "Puyuma"
    elif langs == "è³½å¾·å…‹":
        l_filt = df['Language'] == "Seediq"
    elif langs == "é‚µ":
        l_filt = df['Language'] == "Thao"
    elif langs == "æ‹‰é˜¿é­¯å“‡":
        l_filt = df['Language'] == "Saaroa"
    elif langs == "é”æ‚Ÿ":
        l_filt = df['Language'] == "Yami"
    elif langs == "æ³°é›…":
        l_filt = df['Language'] == "Atayal"
    elif langs == "å¤ªé­¯é–£":
        l_filt = df['Language'] == "Truku"
    elif langs == "é„’":
        l_filt = df['Language'] == "Tsou"
    elif langs == "å¡é‚£å¡é‚£å¯Œ":
        l_filt = df['Language'] == "Kanakanavu"
    elif langs == "è³½å¤":
        l_filt = df['Language'] == "Saisiyat"
    elif langs == "å¸ƒè¾²":
        l_filt = df['Language'] == "Bunun"

    # create a text box for keyword search
    text_box = st.sidebar.text_input('åœ¨ä¸‹æ–¹è¼¸å…¥è¯èªæˆ–æ—èªï¼ŒæŒ‰ä¸‹ENTERå¾Œä¾¿æœƒè‡ªå‹•æ›´æ–°æŸ¥è©¢çµæœ')

    # search for keywords in Mandarin or Formosan
    t_filt = df[texts].str.contains(text_box, flags=re.IGNORECASE)

    # filter the data based on all criteria
    filt_df = df[(s_filt) & (l_filt) & (t_filt)]

    st.markdown(
        """
### æŸ¥è©¢çµæœ
"""
    )
    # display the filtered data
    # st.dataframe(filt_df, width=1600, height=600)
    # st.table(filt_df)

    c = JsCode(
        """
  function(params) {
    return params.data.æ—èª;
  }
  """)

    # CSS to inject contained in a string
    hide_dataframe_row_index = """
            <style>
            .row_heading.level0 {display:none}
            .blank {display:none}
            </style>
            """

    # Inject CSS with Markdown
    st.markdown(hide_dataframe_row_index, unsafe_allow_html=True)

    # add pagination to df
    gb = GridOptionsBuilder.from_dataframe(filt_df)
    gb.configure_pagination(
        paginationAutoPageSize=False, paginationPageSize=20)

    large_font = {"font-size": "1.5em"}

    # if len(text_box) != 0:
    # gb.configure_column(texts, cellRenderer=dynamic_js_code(text_box))

    # gb.configure_column("aa", valueGetter=c, cellRenderer=dynamic_js_code(text_box))
    gb.configure_columns(filt_df.columns, cellStyle=large_font)
    gridOptions = gb.build()
    # AgGrid(filt_df, gridOptions=gridOptions, allow_unsafe_jscode=True, height=650)
    AgGrid(filt_df, gridOptions=gridOptions, allow_unsafe_jscode=True)
    # st.dataframe(filt_df, use_container_width=True)
    st.markdown(
        """
### æŸ¥è©¢çµæœä¸‹è¼‰
"""
    )
    # download link for .csv file
    # st.markdown(get_table_download_link(filt_df), unsafe_allow_html=True)

    output_xlsx = BytesIO()
    output_csv = BytesIO()

    with pd.ExcelWriter(output_xlsx) as writer:
        filt_df.to_excel(writer)

    filt_df.to_csv(output_csv)

    st.download_button(
        label=".xlsxæª”",
        data=output_xlsx.getvalue(),
        file_name="result.xlsx",
        mime="application/vnd.ms-excel"
    )

    st.download_button(
        label=".csvæª”",
        data=output_csv.getvalue(),
        file_name="result.csv",
        mime="text/csv"
    )

    # st.markdown("""### è³‡æ–™çµ±è¨ˆ""")
    # display a data profile report
    # report = get_report()
    # components.html(report, width=800, height=800, scrolling=True)

# Cache the raw data and profile report to speed up subseuqent requests


# @st.cache_data
# def get_data():
    
#     # df = pd.read_pickle('Formosan-Mandarin_sent_pairs_139023entries.pkl')
#     # df = pd.read_pickle(
#     #     'data/Formosan-Mandarin_sent_pairs_20230321.pkl', compression="gzip")
#     # df = df.astype(str, errors='ignore')
#     # df = df.applymap(lambda x: x[1:] if x.startswith(".") else x)
#     # df = df.applymap(lambda x: x.strip())
#     # filt = df.Ch.apply(len) < 5
#     # df = df[~filt]
#     df = get_df_from_google()
#     return df


def load_data(update_timestamp):
    # update_timestamp = get_last_updated_timestamp()
    return cached_data_load(update_timestamp)

@st.cache_data
def cached_data_load(timestamp):
    # Connecting to google sheet
    conn = st.connection("gsheets", type=GSheetsConnection)

    df = conn.read(worksheet="main corpus", ttl=0)
    df = df.astype(str, errors='ignore')
    df = df.applymap(lambda x: x[1:] if x.startswith(".") else x)
    df = df.applymap(lambda x: x.strip())
    filt = df.Ch.apply(len) < 5
    df = df[~filt]

    user_df = conn.read(worksheet="user corpus", ttl=0)
    user_df = user_df.astype(str, errors='ignore')
    user_df = user_df.applymap(lambda x: x[1:] if x.startswith(".") else x)
    user_df = user_df.applymap(lambda x: x.strip())
    filt = user_df.Ch.apply(len) < 5
    user_df = user_df[~filt]

    result_df = df._append(user_df, ignore_index=True)
    return result_df


def get_last_updated_timestamp():
    # Connecting to google sheet
    conn = st.connection("gsheets", type=GSheetsConnection)
    last_ = conn.read(worksheet="last updated", ttl=0)
    last_update_timestamp = int(last_.time[0])
    return last_update_timestamp

# def get_df_from_google():
#     # Connecting to google sheet
#     conn = st.connection("gsheets", type=GSheetsConnection)

#     df = conn.read(worksheet="main corpus", ttl=0)
#     df = df.astype(str, errors='ignore')
#     df = df.applymap(lambda x: x[1:] if x.startswith(".") else x)
#     df = df.applymap(lambda x: x.strip())
#     filt = df.Ch.apply(len) < 5
#     df = df[~filt]

#     user_df = conn.read(worksheet="user corpus", ttl=0)
#     user_df = user_df.astype(str, errors='ignore')
#     user_df = user_df.applymap(lambda x: x[1:] if x.startswith(".") else x)
#     user_df = user_df.applymap(lambda x: x.strip())
#     filt = user_df.Ch.apply(len) < 5
#     user_df = user_df[~filt]

#     result_df = df._append(user_df, ignore_index=True)
#     return result_df

# @st.cache_data
# def get_report():
#     df = get_data()
#     report = ProfileReport(df, title='Report', minimal=True).to_html()
#     return report


def get_table_download_link(df):
    """Generates a link allowing the data in a given panda dataframe to be downloaded
    in:  dataframe
    out: href string
    """
    csv = df.to_csv(index=False)
    # some strings <-> bytes conversions necessary here
    b64 = base64.b64encode(csv.encode()).decode()
    href = f'<a download="result.csv" href="data:file/csv;base64,{b64}">é»æ­¤ä¸‹è¼‰æŸ¥è©¢çµæœ (CSVæª”)</a>'
    return href


def dynamic_js_code(text):
    x = """
  function(params) {{
    var re = /{0}/gi;
    console.log(params.value);
    var news = params.value.replace(re, '<span style="background-color: #f7cac9;">$&</span>');
    return news;
  }}
  """.format(text)

    return JsCode(x)


if __name__ == '__main__':
    main()
